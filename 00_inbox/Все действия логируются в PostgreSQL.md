---
class: note
area: professional
tags:
  - ai
created:
---
**MOC:**

# Все действия логируются в PostgreSQL

> [!tldr] ai review
> 

Отличный вопрос! Давайте детально разберем, как именно работает логирование в системе и что происходит "под капотом" на каждом этапе обработки тикета. Это действительно критически важная часть системы, потому что без правильного логирования вы не сможете оценить эффективность бота и улучшать его работу.

Начну с того, что логирование в этой системе работает не как единовременная запись всей информации, а как последовательный процесс, который отражает жизненный цикл обработки тикета. Представьте это как медицинскую карту пациента, в которую врачи вносят записи на разных этапах лечения - поступление, диагностика, назначение лечения, выписка. Аналогично, система делает записи на каждом этапе работы с тикетом.

## Этап первый: фиксация начала обработки

Когда бот получает webhook от Pyrus о новом тикете, самое первое действие, которое происходит в PostgreSQL - это создание новой записи в таблице ticket_processing. На этом этапе система еще ничего не знает о категории проблемы, об ответе AI или о том, как будет использован ответ. Она знает только базовую информацию - что пришел новый тикет и бот начал его обрабатывать.

В этот момент в базу данных записывается идентификатор тикета из Pyrus, временная метка начала обработки и тип обработки - в данном случае это будет значение "new_ticket", указывающее что это первичная обработка нового обращения, а не повторное обращение к боту через упоминание в комментарии. Также фиксируется время начала обработки, чтобы потом можно было посчитать, сколько времени заняла вся операция.

Эта первичная запись создается сразу, потому что важно зафиксировать сам факт попытки обработки, даже если дальше что-то пойдет не так. Если бот упадет с ошибкой на каком-то этапе, у вас все равно будет запись о том, что обработка началась, и вы сможете расследовать проблему.

## Этап второй: логирование категоризации

После того как бот получил полный контекст тикета через API Pyrus, запускается модуль категоризации. Этот модуль анализирует текст обращения и определяет, к какому типу проблем оно относится - интеграции, маршрутизация, технические сбои и так далее.

Как только категория определена, система обновляет ту же самую запись в таблице ticket_processing, добавляя туда идентификатор категории. Это не создание новой записи, а именно обновление существующей. Технически это выглядит как SQL-запрос UPDATE, который находит нужную запись по её идентификатору и устанавливает значение поля category_id.

Почему это важно логировать? Потому что позже вы захотите проанализировать, в каких категориях бот работает лучше, а в каких хуже. Может оказаться, что бот отлично справляется с вопросами по функционалу платформы, но плохо помогает с техническими сбоями. Эта информация подскажет, какие области базы знаний нужно усилить в первую очередь.

## Этап третий: фиксация работы с RAG

Следующий этап - это обращение к RAG для поиска релевантной информации. Бот формирует поисковый запрос на основе категории и содержания тикета, отправляет его в RAG и получает обратно список документов с оценками релевантности.

В этот момент происходит логирование на двух уровнях. На первом уровне система обновляет основную запись в ticket_processing, добавляя туда агрегированную информацию о результатах поиска в RAG. Сохраняется сам текст запроса, который был отправлен в RAG - это поле rag_query. Также фиксируется общее количество документов, которые вернул RAG - это поле rag_response_count. И самое важное - сохраняется наивысшая оценка релевантности среди всех найденных документов, это поле rag_top_relevance_score.

Давайте разберемся, почему эти данные важны. Текст запроса позволит вам позже понять, правильно ли бот формулирует поисковые запросы. Количество найденных документов показывает, насколько полно RAG покрывает данную тему - если по запросу находится ноль или один документ, возможно база знаний недостаточно полная. А оценка релевантности говорит о том, насколько уверенно RAG нашел подходящую информацию. Если максимальная релевантность низкая, например сорок процентов, это сигнал, что в базе знаний нет хорошего ответа на этот вопрос.

На втором уровне происходит детальное логирование каждого документа, который вернул RAG. Для этого используется отдельная таблица rag_documents_used, связанная с основной записью обработки тикета. Для каждого документа создается отдельная строка, в которой сохраняется идентификатор документа в RAG, его оценка релевантности и позиция в списке результатов - первый он был, второй, третий и так далее.

Эта детализация критически важна для понимания качества работы RAG. Позже, когда вы будете анализировать, почему бот дал неправильный ответ, вы сможете посмотреть, какие именно документы использовались. Возможно окажется, что правильный документ был в результатах, но на пятом месте с низкой оценкой релевантности, и AI его не использовал. Это подскажет, что нужно улучшить ранжирование в RAG.

## Этап четвертый: логирование работы AI

После получения информации из RAG, бот обращается к корпоративному AI для генерации ответа. AI получает на вход исходную проблему пользователя и релевантную информацию из RAG, и генерирует два текста - рекомендацию для сотрудника поддержки и черновик ответа пользователю.

Важно понимать, что сами эти тексты не сохраняются в PostgreSQL. Они публикуются напрямую в тикет через API Pyrus, и остаются только там. В PostgreSQL сохраняются только метаданные об этой генерации. Конкретно - это уровень уверенности AI в своем ответе и длина сгенерированного текста в символах.

Уровень уверенности - это численная оценка от нуля до ста процентов, которую возвращает AI-модель вместе с текстом ответа. Она показывает, насколько модель уверена, что её ответ корректен. Эта метрика чрезвычайно полезна, потому что она позволяет установить пороги. Например, если уверенность ниже семидесяти процентов, бот может явно предупредить сотрудника о необходимости особенно тщательной проверки ответа.

Длина ответа тоже интересная метрика. Иногда бот генерирует очень короткие ответы вроде "информация не найдена", а иногда длинные детальные объяснения. Анализ этих паттернов может показать проблемы - например, если бот систематически дает короткие ответы на определенную категорию вопросов, возможно в базе знаний недостаточно информации по этой теме.

Также на этом этапе фиксируется общее время обработки запроса - от момента получения webhook до момента публикации ответа в тикет. Это позволяет отслеживать производительность системы и выявлять узкие места.

## Этап пятый: обновление после действий сотрудника

Теперь самая интересная часть - логирование того, как сотрудник поддержки использовал ответ бота. Это происходит не сразу, а позже, когда сотрудник фактически отреагирует на тикет и отправит ответ пользователю.

Когда сотрудник публикует свой ответ в тикет, система Pyrus может отправить webhook о новом комментарии. Специальный обработчик в вашей системе анализирует этот комментарий и сравнивает его с тем, что предложил бот. На основе этого сравнения определяется статус использования ответа бота.

Есть три основных статуса. Статус "fully_used" означает, что сотрудник использовал ответ бота практически без изменений или с минимальными правками форматирования. Технически это определяется через вычисление меры сходства текстов - если сходство выше девяноста процентов, считается что ответ использован полностью.

Статус "partially_used" означает, что сотрудник взял ответ бота за основу, но значительно дополнил или изменил его. Сходство текстов в этом случае будет в диапазоне от тридцати до девяноста процентов. Это нормальная ситуация - бот дал направление и базовую информацию, а сотрудник добавил нюансы и персонализацию.

Статус "not_used" означает, что сотрудник написал совершенно другой ответ, никак не связанный с предложением бота. Это может произойти, если бот дал неправильную информацию или не нашел релевантного ответа в RAG.

Когда статус определен, система снова обновляет запись в ticket_processing, устанавливая значение поля answer_usage_status. Также фиксируется временная метка, когда сотрудник отправил ответ пользователю, и вычисляется время от момента публикации ответа бота до момента ответа сотрудника. Это время показывает, сколько сотрудник потратил на проверку и корректировку ответа бота.

Эта метрика особенно ценна для оценки эффективности бота. Если сотрудник использовал ответ бота полностью и при этом потратил всего две минуты от получения ответа бота до отправки пользователю, значит бот действительно сэкономил время. Если же сотрудник потратил двадцать минут на переработку ответа бота, возможно в этом случае бот не был полезен.

## Дополнительное логирование деталей использования

В некоторых случаях может быть полезно логировать не просто факт использования ответа, но и детали того, что именно было изменено. Для этого можно использовать таблицу feedback_corrections, которую я предложил в схеме базы данных.

Когда сотрудник значительно корректирует ответ бота, система может автоматически или по запросу сотрудника создать запись в этой таблице. В ней сохраняется, какая часть ответа бота была некорректной, какой правильный ответ дал сотрудник, и какой тип ошибки это был - фактическая ошибка, устаревшая информация, неполнота или что-то другое.

Эта информация создает обучающий датасет. Накапливая такие корректировки, вы сможете понять системные проблемы. Например, если в большинстве случаев ошибка типа "устаревшая информация" происходит в категории "интеграции", это сигнал, что документация по интеграциям в Confluence обновляется недостаточно часто и ETL-pipeline должен чаще обращаться к этому источнику.

## Практический пример полного цикла логирования

Давайте проследим весь путь логирования на конкретном примере, чтобы все встало на свои места. Представьте, что пользователь создает тикет с вопросом "Как настроить интеграцию с 1С для автоматической синхронизации контрагентов?".

В момент получения webhook, в таблицу ticket_processing создается запись с идентификатором, допустим, пятьсот семь. Фиксируется pyrus_ticket_id равный строке "TASK-12345", processing_timestamp равный текущему времени, например "2025-12-13 14:23:45", и processing_type равный "new_ticket". Все остальные поля пока остаются пустыми или имеют значения по умолчанию.

Модуль категоризации анализирует текст и определяет категорию "integrations" с идентификатором, допустим, один. Запись пятьсот семь обновляется, теперь её поле category_id равно единице.

Бот формирует запрос в RAG: "интеграция 1С синхронизация контрагенты настройка". RAG возвращает пять документов. Самый релевантный имеет оценку восемьдесят пять процентов, это страница из Confluence с инструкцией по настройке интеграции с 1С. Запись пятьсот семь обновляется: rag_query получает значение текста запроса, rag_response_count становится равным пяти, rag_top_relevance_score равен восемьдесят пять.

Одновременно в таблицу rag_documents_used создаются пять записей, по одной на каждый документ. Первая запись имеет relevance_score равный восемьдесят пять и document_rank равный один, вторая - семьдесят два и два, и так далее.

AI генерирует ответ на основе найденной информации. Модель возвращает детальную инструкцию по настройке интеграции длиной девятьсот символов и уверенность в ответе девяносто процентов. Запись пятьсот семь обновляется: generated_response_length становится девятьсот, ai_confidence_score равен девяносто. Весь процесс от получения webhook до публикации ответа занял три секунды, поэтому processing_duration_ms равен три тысячи миллисекунд.

Ответ бота публикуется в тикет в Pyrus. Пока сотрудник не отреагировал, поле answer_usage_status остается в статусе "pending".

Через пятнадцать минут сотрудник поддержки проверяет ответ бота, добавляет небольшое уточнение про версии 1С и отправляет ответ пользователю. Система обнаруживает, что сходство текстов девяносто пять процентов - ответ использован практически полностью. Запись пятьсот семь обновляется последний раз: answer_usage_status становится "fully_used", support_response_timestamp фиксируется как "2025-12-13 14:38:45", и time_to_support_response_sec вычисляется как девятьсот секунд - пятнадцать минут.

Теперь в базе данных есть полная картина обработки этого тикета. Вы можете увидеть, что бот правильно определил категорию, нашел релевантную информацию в RAG с высокой оценкой, сгенерировал уверенный ответ, и сотрудник практически полностью его использовал, потратив всего пятнадцать минут. Это успешный кейс работы бота.

## Агрегация и анализ логов

Вся эта детальная информация в отдельных записях позволяет строить мощную аналитику. Например, чтобы посчитать эффективность бота по категории "интеграции" за последнюю неделю, вы просто делаете SQL-запрос, который выбирает все записи с category_id равным один за нужный период, и считаете процент записей где answer_usage_status равен "fully_used".

Или вы можете найти все случаи, где бот дал ответ с низкой уверенностью, но сотрудник все равно его использовал. Это интересный паттерн - возможно AI слишком осторожен в оценках, или наоборот, найти случаи где бот был очень уверен, но ответ не использовался - это тревожный сигнал о калибровке модели.

Таблица bot_performance_metrics, которую я предложил в схеме базы данных, как раз и содержит такие агрегированные подсчеты, чтобы не делать сложные запросы каждый раз. Она обновляется автоматически триггерами или периодическими задачами и дает быстрый доступ к ключевым метрикам.

Важно понимать, что логирование - это не просто техническая необходимость для отладки. Это фундамент для непрерывного улучшения системы. Без детальных логов вы летите вслепую, не зная, что работает, а что нет. С хорошим логированием каждый тикет становится источником данных для обучения и оптимизации.

Стало понятнее, как устроен процесс логирования? Может быть есть какие-то специфические аспекты, которые вы хотели бы разобрать подробнее - например, как именно технически реализовать сравнение текстов для определения статуса использования ответа, или как автоматизировать обновление статусов при получении событий из Pyrus?
### Additional materials