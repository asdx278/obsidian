---
class: note
area: professional
tags:
  - ai
created: 2025-12-13
---
**MOC: [[MOC - Professional]]**

# AI_helper_bot - план реализации

> [!tldr] ai review
> 

Изучил ваши обновления! Вижу, что вы приняли стратегическое решение упростить архитектуру, используя нативные возможности Pyrus вместо отдельной базы данных PostgreSQL, и сфокусироваться только на тикетах Pyrus как источнике знаний, исключив Confluence. Это очень разумный подход для первой итерации - система становится более цельной и проще в поддержке.

Позвольте предложить детальный пошаговый план реализации, который учитывает эти изменения и позволит вам двигаться итеративно, получая работающие результаты на каждом этапе.

## Подготовительный этап: проектирование структуры данных в Pyrus

Прежде чем начинать разработку, критически важно продумать, как именно вы будете хранить метаданные и логи в формах Pyrus. Это фундамент всей системы, и правильная структура сейчас избавит вас от переделок позже.

Вам потребуется создать несколько специализированных форм в Pyrus, каждая из которых будет выполнять роль таблицы из реляционной базы данных. Первая форма - это журнал обработки тикетов. Каждый раз, когда бот обрабатывает тикет, создается новая задача в этой форме. Форма должна содержать поля для идентификатора исходного тикета, временной метки обработки, типа обработки (новый тикет или упоминание бота), категории проблемы (это поле-справочник), текста запроса в RAG, количества найденных документов, оценки релевантности, уверенности AI, длины сгенерированного ответа, статуса использования ответа сотрудником.

Вторая форма - журнал запусков ETL. Каждый запуск ETL-процесса создает задачу здесь. Поля включают временную метку запуска, тип запуска (по расписанию или ручной), статус выполнения, количество обработанных тикетов, количество добавленных записей в RAG, количество найденных персональных данных, идентификатор версии в RAG, время выполнения, сообщения об ошибках если были.

Третья форма - журнал версий RAG. Это ключевая форма для механизма версионирования. Каждая версия данных в RAG получает запись здесь. Поля: идентификатор версии, связь с запуском ETL, признак активности версии, описание изменений, общее количество документов в версии, временная метка создания и активации.

Четвертая форма - форма актуализации RAG. Это та самая форма, через которую сотрудники поддержки будут добавлять новые знания вручную. Поля: ссылка на исходный тикет где возникла проблема, категория знания, описание что нужно добавить или исправить, текст новой информации, статус обработки ботом.

Пятая форма - форма отката версии RAG. Через эту форму администратор может инициировать откат к предыдущей версии. Поля: целевая версия для отката (выбор из справочника версий), причина отката, статус выполнения отката.

Также потребуется создать несколько справочников. Справочник категорий тикетов с названием категории и описанием. Справочник версий RAG - динамический справочник, который автоматически пополняется из формы журнала версий. Справочник статусов использования ответа с вариантами: ожидается, использован полностью, использован частично, не использован.

На этом этапе нарисуйте структуру форм на бумаге или в любом инструменте моделирования, покажите команде, соберите обратную связь. Убедитесь, что структура покрывает все ваши потребности в хранении данных и построении отчетов. Только после утверждения структуры переходите к созданию форм в Pyrus.

## Этап первый: минимальный рабочий прототип бота

Цель этого этапа - создать самую простую версию бота, которая демонстрирует основной флоу работы. Бот должен уметь получать webhook о новом тикете, обращаться к RAG, генерировать ответ с помощью AI и публиковать его обратно в тикет. Никакой категоризации, никакой сложной логики - только базовый путь от запроса до ответа.

Начните с настройки webhook в Pyrus. Выберите тестовую форму для обращений пользователей и настройте отправку webhook на ваш сервер при создании новой задачи. Если у вас еще нет публичного эндпоинта, используйте сервисы типа ngrok для тестирования на локальной машине.

Создайте простейший workflow в n8n. Первый узел - Webhook trigger, который принимает уведомление от Pyrus. Второй узел - HTTP Request к API Pyrus для получения полного контекста задачи. На этом этапе просто извлеките описание проблемы из тела задачи. Третий узел - HTTP Request к вашему корпоративному RAG. Отправьте описание проблемы как поисковый запрос. Четвертый узел - обработка ответа от RAG, извлечение наиболее релевантных фрагментов. Пятый узел - HTTP Request к корпоративному AI с промптом, который включает исходный вопрос и информацию из RAG. Шестой узел - HTTP Request к API Pyrus для публикации ответа AI как комментария в тикет.

Протестируйте этот workflow на нескольких реальных тикетах. Важно убедиться, что все интеграции работают корректно - webhook приходит, API отвечают, комментарии публикуются. На этом этапе не беспокойтесь о качестве ответов или структуре данных - просто убедитесь, что технически все работает end-to-end.

Когда базовый флоу заработал, добавьте минимальное логирование. После каждой успешной обработки тикета создавайте задачу в форме журнала обработки через API Pyrus. Заполняйте только базовые поля - идентификатор тикета, время обработки, текст запроса в RAG. Остальные поля оставьте пустыми или со значениями по умолчанию.

Результат этого этапа - у вас есть работающий бот, который может обрабатывать тикеты, и вы видите логи обработки в отдельной форме Pyrus. Это дает вам платформу для дальнейшего развития функциональности.

## Этап второй: добавление категоризации и улучшение логирования

На этом этапе вы добавляете интеллект в обработку тикетов. Бот должен научиться определять категорию проблемы и использовать эту информацию для улучшения поиска в RAG.

Создайте справочник категорий в Pyrus со всеми категориями, которые мы обсуждали - интеграции, маршрутизация, функционал платформы, технические сбои, права доступа, отчетность, прочее. Убедитесь, что этот справочник доступен для выбора в форме журнала обработки.

Добавьте в ваш n8n workflow новый узел категоризации сразу после получения контекста тикета. Реализовать категоризацию можно двумя способами. Первый, простой способ - это правила на основе ключевых слов. Создайте узел Function в n8n, который анализирует текст описания проблемы и ищет определенные слова. Например, если в тексте встречаются слова "интеграция", "API", "синхронизация", "обмен данными", то категория - интеграции. Если встречаются "маршрутизация", "правила", "переход", "этап" - категория маршрутизация. Этот подход работает удивительно хорошо для начала, хотя и не идеален.

Второй способ, более продвинутый - использовать корпоративный AI для категоризации. Добавьте дополнительный вызов AI перед основным запросом, где AI получает описание проблемы и список доступных категорий, и должен вернуть только название наиболее подходящей категории. Этот подход точнее, но требует двух обращений к AI на каждый тикет.

После определения категории модифицируйте запрос к RAG. Добавьте категорию как фильтр или как часть поискового запроса. Если ваш RAG поддерживает фильтрацию по метаданным, используйте фильтр category equals найденная_категория. Если нет, добавьте категорию в начало текстового запроса - например, "Категория интеграции: как настроить синхронизацию с 1С".

Расширьте логирование. Теперь в форму журнала обработки записывайте не только базовые поля, но и категорию, количество документов найденных RAG, максимальную оценку релевантности из RAG, уровень уверенности AI (если ваш AI возвращает такую метрику). Все эти данные будут бесценны для анализа эффективности.

Протестируйте категоризацию на разнообразных тикетах. Проверьте, правильно ли определяются категории. Скорее всего вам придется несколько раз корректировать правила или промпт для AI, чтобы достичь приемлемой точности. Не стремитесь к совершенству на этом этапе - семьдесят-восемьдесят процентов правильной категоризации это уже отличный результат для начала.

Результат этого этапа - бот умеет категоризировать проблемы и использует эту информацию для улучшения ответов, а логи содержат детальную информацию о каждой обработке.

## Этап третий: создание ETL-pipeline для обновления RAG

Сейчас ваш RAG работает с какими-то начальными данными, но нет механизма их обновления. Пришло время создать ETL-процесс, который будет регулярно пополнять базу знаний из закрытых тикетов.

Создайте отдельный workflow в n8n для ETL-процесса. Настройте его запуск по расписанию - например, каждую ночь в три часа. Первый узел - Schedule Trigger с настройкой cron-выражения для ежедневного запуска.

Второй узел - создание записи о начале ETL в форме журнала запусков через API Pyrus. Укажите текущее время, тип запуска "по расписанию", статус "начат". Запомните идентификатор созданной задачи - он понадобится для обновления статуса.

Третий узел - генерация идентификатора новой версии. Используйте формат который мы обсуждали - текущая дата плюс тип обновления. Например, "2025-12-15_scheduled_01". Счетчик на конце нужен на случай если за день будет несколько запусков.

Четвертый узел - извлечение закрытых тикетов из Pyrus. Используйте API Pyrus с параметрами фильтрации: статус равен закрыт, дата закрытия за последние семь дней, есть положительная оценка от пользователя. Pyrus API возвращает список задач. Проходите по каждой задаче и извлекайте её полное содержимое - описание проблемы, все комментарии, решение.

Пятый узел - это самый важный и сложный - модуль трансформации. Здесь нужно использовать Python, потому что логика слишком сложная для n8n. Создайте отдельный микросервис на Python (можно как простой Flask или FastAPI endpoint), который принимает на вход сырые данные тикета и возвращает структурированный документ для загрузки в RAG.

Этот Python-сервис должен выполнять несколько функций. Во-первых, извлечение полезной информации из тикета. Определите, какие комментарии были от сотрудников поддержки и содержали решение проблемы. Игнорируйте автоматические комментарии, комментарии от ботов, просто благодарности пользователя. Во-вторых, структурирование в формат который мы обсудили ранее - проблема, решение, итог. В-третьих, очистка от персональных данных. Используйте регулярные выражения для email и телефонов, замените конкретные имена и названия компаний на обобщения. В-четвертых, создание метаданных - определите категорию тикета из его полей Pyrus, добавьте теги на основе ключевых слов, укажите идентификатор версии.

Шестой узел - отправка подготовленных документов в RAG через API. Для каждого обработанного тикета отправляйте JSON-структуру документа. Убедитесь, что в метаданных правильно указан version_id и is_active установлен в false - новая версия пока не активна.

Седьмой узел - подсчет статистики. Сколько тикетов было обработано, сколько документов создано в RAG, сколько персональных данных найдено и очищено. Сохраните эти цифры.

Восьмой узел - создание записи о новой версии в форме журнала версий RAG. Укажите идентификатор версии, связь с текущим запуском ETL, количество документов, признак активности false.

Девятый узел - активация новой версии. Это критический момент. Найдите текущую активную версию в журнале версий и обновите её, установив is_active в false. Затем обновите запись новой версии, установив is_active в true и зафиксировав время активации. С этого момента RAG начнет использовать новые данные при поиске.

Десятый узел - обновление записи о запуске ETL. Установите статус "завершен", заполните все поля статистики, укажите время выполнения.

Одиннадцатый узел - обработка ошибок. Если на любом из предыдущих шагов произошла ошибка, обновите запись ETL установив статус "ошибка" и сохранив текст ошибки. Отправьте уведомление в корпоративный мессенджер команде поддержки.

Протестируйте ETL сначала вручную, не дожидаясь расписания. Запустите workflow и внимательно отслеживайте каждый шаг. Проверьте что тикеты извлекаются правильно, что персональные данные очищаются, что документы появляются в RAG. После нескольких успешных ручных запусков активируйте автоматический запуск по расписанию.

Результат этого этапа - у вас есть автоматический процесс обновления базы знаний, который работает ежедневно и пополняет RAG реальными кейсами из практики поддержки.

## Этап четвертый: механизм ручной актуализации RAG

Иногда сотрудникам поддержки нужно быстро добавить важную информацию в базу знаний, не дожидаясь ночного запуска ETL. Для этого создаете форму ручной актуализации и обработчик для неё.

Создайте форму "Актуализация RAG" в Pyrus. Поля формы: ссылка на тикет (необязательное поле-связь, если актуализация связана с конкретным тикетом где обнаружилась проблема), категория знания (выбор из справочника категорий), краткое описание что добавляется или исправляется, подробный текст новой информации (большое текстовое поле где сотрудник пишет в структурированном виде что нужно добавить в базу знаний), статус обработки (справочник: ожидает, обрабатывается, добавлено, отклонено).

Настройте webhook на эту форму для отправки уведомлений при создании новой задачи.

Создайте отдельный workflow в n8n для обработки ручных актуализаций. Первый узел - Webhook trigger для приема уведомлений о новых задачах актуализации.

Второй узел - получение полного контекста задачи актуализации через API Pyrus. Извлеките все заполненные поля.

Третий узел - обновление статуса задачи на "обрабатывается" через API Pyrus. Это дает сотруднику обратную связь что его запрос принят в работу.

Четвертый узел - валидация и очистка данных. Вызовите тот же Python-сервис очистки персональных данных, который используется в ETL. Передайте текст новой информации, получите обратно очищенную версию.

Пятый узел - формирование документа для RAG. Создайте JSON-структуру с полем content содержащим очищенный текст, и метаданными указывающими что это ручная актуализация, категорию, текущую временную метку, специальный маркер source_type равный manual_update.

Шестой узел - отправка документа в RAG через API. В отличие от ETL, здесь документ сразу создается с is_active равным true и version_id текущей активной версии - ручные актуализации сразу становятся доступными для поиска.

Седьмой узел - создание записи в форме журнала обработки или в специальной форме для ручных актуализаций, если вы её создали. Зафиксируйте кто, когда и какую информацию добавил.

Восьмой узел - обновление статуса задачи актуализации на "добавлено" и публикация комментария с подтверждением что информация успешно добавлена в базу знаний. Можете указать идентификатор созданного документа в RAG для трассируемости.

Девятый узел - обработка ошибок. Если что-то пошло не так, обновите статус на "отклонено", опубликуйте комментарий с описанием проблемы, отправьте уведомление администратору.

Протестируйте процесс, создав несколько тестовых задач актуализации. Убедитесь что информация действительно добавляется в RAG и становится доступной для поиска ботом.

Результат этого этапа - сотрудники поддержки могут оперативно пополнять базу знаний когда обнаруживают пробелы, не дожидаясь автоматического обновления.

## Этап пятый: механизм версионирования и отката

Теперь реализуем возможность откатиться к предыдущей версии базы знаний если обновление привело к проблемам.

Создайте форму "Откат версии RAG" в Pyrus. Поля: версия для отката (выбор из справочника версий RAG, который автоматически пополняется из формы журнала версий), причина отката (текстовое поле где администратор объясняет почему делается откат), статус выполнения (ожидает, выполняется, завершен, ошибка).

Настройте webhook на эту форму.

Создайте workflow в n8n для обработки откатов. Первый узел - Webhook trigger.

Второй узел - получение информации о задаче отката и извлечение целевой версии.

Третий узел - валидация. Проверьте что выбранная версия существует в журнале версий и не является уже активной. Если выбрана текущая активная версия, это ошибка - откатываться некуда.

Четвертый узел - обновление статуса задачи отката на "выполняется".

Пятый узел - деактивация текущей версии. Найдите в форме журнала версий запись с is_active равным true и обновите её, установив is_active в false.

Шестой узел - активация целевой версии. Обновите запись выбранной версии в журнале, установив is_active в true и зафиксировав время активации.

Важный момент - вам нужно убедиться, что ваш RAG правильно обрабатывает переключение версий. Когда бот делает запрос к RAG, он должен явно указывать какую версию использовать. Модифицируйте workflow бота чтобы перед каждым запросом к RAG он определял текущую активную версию из формы журнала версий и передавал её идентификатор в запросе к RAG. Если ваш RAG не поддерживает такую фильтрацию нативно, нужно будет реализовать wrapper API который добавляет эту логику.

Седьмой узел - создание записи об откате для аудита. В форму журнала версий или в отдельную форму откатов зафиксируйте от какой версии к какой был откат, кто инициировал, когда, по какой причине.

Восьмой узел - обновление статуса задачи отката на "завершен" с комментарием о успешном выполнении.

Девятый узел - отправка уведомления в корпоративный мессенджер команде поддержки что произошел откат базы знаний. Это важно чтобы все были в курсе изменения.

Десятый узел - обработка ошибок с соответствующими уведомлениями.

Протестируйте механизм отката в безопасной среде. Создайте несколько тестовых версий, выполните откат между ними, убедитесь что бот действительно начинает использовать данные из выбранной версии.

Результат этого этапа - у вас есть надежный механизм отката который позволяет быстро вернуться к предыдущему рабочему состоянию базы знаний в случае проблем.

## Этап шестой: обработка упоминаний бота в комментариях

Добавьте функциональность обработки случаев когда сотрудник упоминает бота в комментарии к существующему тикету.

Настройте дополнительный webhook в Pyrus на событие создания нового комментария в форме обращений пользователей.

Создайте новый workflow в n8n или расширьте существующий. Первый узел - Webhook trigger для комментариев.

Второй узел - проверка упоминания бота. Проанализируйте текст комментария - содержит ли он упоминание вашего бота (обычно это специальный маркер типа @bot_helper или определенная команда). Если упоминания нет, workflow завершается без действий.

Третий узел - получение полной истории задачи через API Pyrus. Извлеките все комментарии, отфильтруйте комментарии от других ботов, соберите всю информацию о задаче.

Четвертый узел - формирование расширенного контекста. Объедините исходное описание проблемы со всеми комментариями в один связный текст который передадите в RAG. Важно структурировать информацию так чтобы было понятно что это история диалога, а не просто набор фраз.

Пятый узел - категоризация. Если у задачи уже есть категория из первичной обработки, используйте её. Если нет или если история диалога показывает что проблема сместилась в другую область, пере-категоризируйте на основе всего контекста.

Шестой узел - запрос к RAG с расширенным контекстом.

Седьмой узел - генерация ответа AI с учетом всей истории.

Восьмой узел - публикация ответа в тикет.

Девятый узел - логирование в форму журнала обработки с типом "упоминание в комментарии".

Протестируйте функциональность создав тестовый тикет, пусть он пройдет первичную обработку ботом, затем добавьте комментарий с дополнительной информацией и упомяните бота. Проверьте что бот корректно обрабатывает расширенный контекст.

Результат этого этапа - бот может помогать не только при создании тикета, но и в процессе обсуждения, когда появляется дополнительная информация.

## Этап седьмой: отслеживание использования ответов бота

Реализуйте механизм который отслеживает, как сотрудники поддержки используют ответы бота - полностью, частично или совсем не используют.

Создайте дополнительный workflow который срабатывает при закрытии тикета или при публикации ответа пользователю от сотрудника поддержки.

Первый узел - Webhook trigger на событие обновления задачи с фильтром на смену статуса или добавление комментария от сотрудника.

Второй узел - получение информации о задаче и поиск соответствующей записи в форме журнала обработки по идентификатору тикета.

Третий узел - извлечение ответа бота и ответа сотрудника. Найдите комментарий который опубликовал бот (черновик ответа пользователю), и комментарий который отправил сотрудник пользователю.

Четвертый узел - сравнение текстов. Это можно сделать простым способом через подсчет процента совпадающих слов, или более продвинутым способом через вычисление семантического сходства с помощью AI. Если сходство больше девяноста процентов - ответ использован полностью. Если от тридцати до девяноста - частично. Если меньше тридцати - не использован.

Пятый узел - обновление записи в форме журнала обработки. Установите поле статуса использования в соответствующее значение. Зафиксируйте время когда сотрудник отправил ответ и вычислите разницу с временем когда бот дал свою рекомендацию.

Шестой узел - если ответ бота не был использован или использован частично, можно автоматически создать напоминание сотруднику о возможности актуализировать базу знаний через форму актуализации RAG.

Результат этого этапа - вы получаете метрики эффективности бота которые показывают насколько полезны его рекомендации в реальной работе.

## Этап восьмой: аналитика и отчетность

Создайте механизмы для анализа накопленных данных и генерации отчетов о работе бота.

Используйте встроенные возможности отчетности Pyrus. Создайте несколько отчетов на основе формы журнала обработки. Первый отчет - общая статистика по категориям: количество тикетов в каждой категории, процент полностью использованных ответов, процент частично использованных, процент не использованных. Второй отчет - динамика по времени: сколько тикетов обрабатывалось каждый день, как менялась эффективность бота. Третий отчет - проблемные области: тикеты где уверенность AI была низкой, или где ответ не был использован сотрудником.

Настройте автоматическую генерацию еженедельного сводного отчета. Создайте workflow в n8n который запускается каждый понедельник, собирает статистику за прошлую неделю из формы журнала обработки, формирует текстовый отчет и отправляет его в корпоративный мессенджер команде поддержки или создает задачу в Pyrus с этим отчетом.

Отчет должен включать ключевые метрики: общее количество обработанных тикетов, процент успешных ответов, среднее время от ответа бота до ответа сотрудника, топ три категории по количеству обращений, категории где бот работает лучше всего, категории где есть проблемы, количество ручных актуализаций RAG, количество запусков ETL и их статус.

Результат этого этапа - у руководства и команды есть четкое понимание как работает бот, где он полезен, а где нуждается в улучшении.

## Этап девятый: оптимизация и масштабирование

После того как система поработала несколько недель и вы собрали достаточно данных, пришло время оптимизации.

Проанализируйте логи и метрики. Найдите паттерны - какие категории чаще всего приводят к низкой уверенности AI, какие запросы к RAG возвращают мало релевантных результатов, где персональные данные чаще всего пропускаются очисткой.

На основе анализа улучшите правила категоризации. Если определенные типы вопросов систематически попадают в неправильную категорию, скорректируйте ключевые слова или промпт для AI-категоризатора.

Обогатите базу знаний. Если видите что по определенным темам бот часто не находит ответов, проведите целенаправленную актуализацию RAG по этим темам. Попросите опытных сотрудников поддержки создать несколько задач актуализации с детальными инструкциями по этим проблемным областям.

Улучшите очистку персональных данных. Если в логах ETL видите что какие-то паттерны персональных данных пропускаются, добавьте дополнительные регулярные выражения или NER-модели в Python-сервис.

Оптимизируйте промпты для AI. Экспериментируйте с формулировками инструкций для AI - как описывается задача, какие примеры даются, как структурирован вывод. Даже небольшие изменения в промпте могут значительно улучшить качество ответов.

Если нагрузка выросла и бот начинает работать медленно, рассмотрите контейнеризацию компонентов. Упакуйте Python-сервис очистки данных в Docker-контейнер, разверните его в Kubernetes для автоматического масштабирования при росте нагрузки.

Результат этого этапа - система работает стабильно, эффективно и готова к увеличению нагрузки.

## Общие рекомендации по реализации

Работайте итеративно - каждый этап должен давать работающий результат который можно протестировать и получить обратную связь. Не пытайтесь реализовать все сразу. Важнее запустить базовую версию быстро и начать собирать реальные данные использования, чем месяцами разрабатывать идеальную систему которая может не соответствовать реальным потребностям.

Активно вовлекайте сотрудников поддержки на всех этапах. Показывайте им промежуточные результаты, собирайте обратную связь, учитывайте их пожелания. Они будут основными пользователями системы и их вовлеченность критична для успеха проекта.

Документируйте все решения и изменения. Создайте пространство в Confluence или набор документов где фиксируете архитектурные решения, структуру форм, логику workflows, особенности интеграций. Это поможет при поддержке системы и передаче знаний новым членам команды.

Планируйте резервное время на каждый этап. Почти всегда возникают неожиданные сложности - API работают не так как описано в документации, интеграции требуют дополнительной настройки, обнаруживаются граничные случаи. Закладывайте на каждый этап на тридцать-пятьдесят процентов больше времени чем кажется необходимым.

Начинайте с качества данных, а не количества. Лучше иметь в RAG сто отлично структурированных и очищенных документов, чем тысячу плохо обработанных. Качество базы знаний напрямую определяет качество ответов бота.

Этот план дает вам четкую дорожную карту от начала до полностью работающей системы. Какие этапы вам кажутся наиболее критичными или вызывают больше всего вопросов?

[[backlog]]
### Additional materials